TIS的`v3.8.0`版本终于要与大家见面了，`v3.8.0`着重在以下几方面进行了功能加强和升级。

1. 支持利用`Flink Checkpoint`恢复因意外宕机而中断的Flink Job任务 

   用户运行的Flink Job 任务经常会因为各种原因导致意外停止，例如：机房断电等。如需要恢复中断的Flink 
   Job需要用户事先手动触发Savepoint存储来恢复。而机房断电属于不可预测事件，用户无法提前预测，所以只能对中断的Flink Job进行重新部署，这个流程特别费时，且之前保存的StateBackend也会丢失。

   因此，在TIS中提供了通过Flink Checkpoint机制来恢复Job的方式，用户只需要在部署Flink 
   Job过程中，开启Checkpoint机制、并设置持久化StatebackEnd，就可以方便恢复因意外中断的Flink Job任务。https://github.com/datavane/tis/issues/224

2. 与Doris最新版本的兼容性提升
   
   使用Doris最新版本2.0.1与TIS兼容性优化，对`Sequence列模型`与`批量删除`的设置体验进行优化，为用户提供整库导入Doris实现实时数仓方案提供了最佳技术手段。

3. 提供TIS插件开发工具

   随着TIS功能不断壮大，会有越来越多的开发者加入到TIS的生态构建中来。 TIS内部使用了微内核架构设计，践行OCP原则（对修改封闭，对新加功能开放），为了让用户愉快地加入到TIS生态构建中来，从`v3.8.
   0`版本开始，会陆续提供一系列工具和技术分享文档，让用户可以独立地开发新的大数据集成插件，或者完善既有的TIS插件功能以满足自己的业务需求。
   
   新添加的插件参考文档：
   1. [插件实现开发详细说明](https://tis.pub/docs/3.8.0/develop/plugin-develop-detail)
   2. [插件开发流程说明](https://tis.pub/docs/3.8.0/develop/plugin-develop)
   3. [插件工具类参考](https://tis.pub/docs/3.8.0/develop/plugin-utils-reference)
4. Hive Reader 支持
   T+1离线分析会将计算结果导入Hive的分布式文件系统中。本版本（v3.8.0）提供Hive Reader用户可以通过简单设置 将Hive中的数据导入到Doris、ElasticSearch、StarRocks、各种关系型数据库中。
5. 重构 Aliyun OSS、FTP、HDFS
   针对分布式文件端类型的支持，之前在TIS中对以上各种类型的数据端是各自实现的，但是在实现过程发现，每种数据类型都有压缩，数据Format（CSV、TEXT）的逻辑在需要重复实现，不同的仅仅是每种类型的文件流的获取方式。
   在本版本（v3.8.0）中，将文件流获取的方式单独抽取出来，其他执行逻辑实现重用。这样有利于在TIS中对分布式式文件类型端的维护，也可大大简化今后在TIS中接入同类型数据端的复杂程度。https://github.com/datavane/tis/issues/253
6. 重构MongoDB Reader功能
   
   * 支持MongoDB，多Collection选择，
   * 针对MongoDB没有固定Schema的特性，TIS中加入了预判MongoDB Colection Scheam的功能，原理是预先从MongoDB 
     Collection中读取一定数量的记录数，TIS中会针对记录各Column值来猜测列类型，最终再由用户来确定类型进行微调。这样可以免去用户为MongoDB 
     Collection设置Schema的繁琐流程，从而大大提高部署效率。
   * 针对MongoDB Collection的 提供给用户拆解Document类型的字段的途径、手段。可以将Document字段中的内容，打平、Sink到下游数据端中。

   https://github.com/datavane/tis/issues/254
7. 优化Kerberos认证支持
   优化TIS中kerberos认证的支持，支持Hive、HDFS等数据端
   https://github.com/datavane/tis/issues/127
8. 云原生方面的支持
   支持Aliyun HDFS 的JindoFS类型的导入方式，通过 JindoFS类型的导入方式，性能比传统HDFS效率高3倍。



   
   
   
